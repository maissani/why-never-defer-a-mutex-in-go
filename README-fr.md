# POC - Impact du defer sur les performances des Mutex en Go

## ğŸ¯ Objectif

Ce POC (Proof of Concept) dÃ©montre pourquoi l'utilisation de `defer` avec les mutex est une **mauvaise pratique** qui peut drastiquement impacter les performances d'une application Go sous charge concurrente.

## ğŸš¨ Le ProblÃ¨me

Beaucoup de dÃ©veloppeurs Go utilisent systÃ©matiquement `defer` pour libÃ©rer les mutex :

```go
mu.Lock()
defer mu.Unlock()  // âŒ MAUVAISE PRATIQUE
// ... traitement long ...
```

Cette approche maintient le mutex verrouillÃ© pendant **toute la durÃ©e de la fonction**, crÃ©ant un goulot d'Ã©tranglement critique.

## âœ… La Solution

LibÃ©rer le mutex immÃ©diatement aprÃ¨s les opÃ©rations critiques :

```go
mu.Lock()
// ... opÃ©ration critique rapide ...
mu.Unlock()  // âœ… BONNE PRATIQUE

// ... traitement long SANS le mutex ...
```

## ğŸ“Š RÃ©sultats du Benchmark

Les tests comparent deux serveurs HTTP identiques, avec la seule diffÃ©rence Ã©tant la gestion des mutex :

### Latence moyenne par requÃªte

| Concurrence | Bad Server (defer) | Good Server | **AmÃ©lioration** |
|-------------|-------------------|-------------|------------------|
| 1 goroutine | 11.12 ms | 11.20 ms | -0.7% |
| 10 goroutines | **106.97 ms** | 11.89 ms | **88.9%** |
| 50 goroutines | **419.25 ms** | 13.84 ms | **96.7%** |
| 100 goroutines | **558.35 ms** | 16.17 ms | **97.1%** |

### Throughput (requÃªtes/seconde)

- **Bad Server** : ~87-90 req/s (constant, peu importe la concurrence)
- **Good Server** : 
  - 1 goroutine : 88 req/s
  - 10 goroutines : **687 req/s** 
  - 50 goroutines : 367 req/s
  - 100 goroutines : 316 req/s

## ğŸ” Analyse

1. **Sans concurrence** (1 goroutine) : Performances identiques, pas de contention
2. **Avec concurrence** : Le serveur "bad" devient un **goulot d'Ã©tranglement** car une seule goroutine peut traiter Ã  la fois
3. **Impact exponentiel** : Plus la concurrence augmente, plus la dÃ©gradation est importante (jusqu'Ã  **97% plus lent**)

## ğŸ—ï¸ Structure du Projet

- `bad_server.go` : Serveur HTTP avec mutex + defer (port 8081)
- `good_server.go` : Serveur HTTP avec mutex bien utilisÃ©s (port 8082)
- `benchmark_test.go` : Tests de charge comparatifs
- `run_benchmark.sh` : Script d'automatisation des tests

## ğŸš€ Installation et ExÃ©cution

### PrÃ©requis
- Go 1.21 ou supÃ©rieur
- Git (pour cloner le projet)

### Installation

1. Cloner le projet :
```bash
git clone <url-du-repo>
cd poc
```

2. Installer les dÃ©pendances :
```bash
go mod download
go mod tidy
```

### ExÃ©cution des Benchmarks

#### MÃ©thode 1 : Script automatique (RecommandÃ©)

Le script `run_benchmark.sh` gÃ¨re automatiquement le dÃ©marrage des serveurs et l'exÃ©cution des tests :

```bash
chmod +x run_benchmark.sh
./run_benchmark.sh
```

Le script va :
1. DÃ©marrer les deux serveurs en arriÃ¨re-plan
2. VÃ©rifier qu'ils rÃ©pondent correctement
3. Lancer les benchmarks pendant 10 secondes par test
4. Afficher les rÃ©sultats de latence comparative
5. ArrÃªter proprement les serveurs

#### MÃ©thode 2 : ExÃ©cution manuelle

Si vous prÃ©fÃ©rez contrÃ´ler chaque Ã©tape :

1. **Terminal 1** - DÃ©marrer le serveur "bad" :
```bash
go run bad_server.go
# Le serveur Ã©coute sur http://localhost:8081
```

2. **Terminal 2** - DÃ©marrer le serveur "good" :
```bash
go run good_server.go
# Le serveur Ã©coute sur http://localhost:8082
```

3. **Terminal 3** - VÃ©rifier que les serveurs fonctionnent :
```bash
# Tester le serveur "bad"
curl http://localhost:8081/stats

# Tester le serveur "good"
curl http://localhost:8082/stats
```

4. **Terminal 3** - Lancer les benchmarks :
```bash
# Benchmarks complets (10 secondes par test)
go test -bench=. -benchtime=10s benchmark_test.go

# Version rapide (1 seconde par test)
go test -bench=. -benchtime=1s benchmark_test.go

# Uniquement les tests de latence
go test -run TestLatencyComparison -v benchmark_test.go
```

### InterprÃ©ter les RÃ©sultats

Les benchmarks affichent :
- **ns/op** : Nanosecondes par opÃ©ration
- **ms/req** : Millisecondes par requÃªte (plus facile Ã  lire)
- **req/s** : RequÃªtes par seconde (throughput)

Plus la concurrence augmente, plus la diffÃ©rence entre les deux approches devient Ã©vidente.

## ğŸ’¡ LeÃ§ons ClÃ©s

1. **N'utilisez `defer` avec les mutex que pour des opÃ©rations trÃ¨s courtes**
2. **LibÃ©rez les mutex dÃ¨s que possible** pour permettre le parallÃ©lisme
3. **Copiez les donnÃ©es nÃ©cessaires** puis libÃ©rez le mutex avant le traitement
4. **L'impact sur les performances peut Ãªtre catastrophique** (jusqu'Ã  97% de dÃ©gradation)

## ğŸ“ Conclusion

Ce POC prouve que l'utilisation systÃ©matique de `defer` avec les mutex est une anti-pattern qui peut transformer votre application en systÃ¨me mono-thread de facto, annulant tous les bÃ©nÃ©fices de la concurrence Go.